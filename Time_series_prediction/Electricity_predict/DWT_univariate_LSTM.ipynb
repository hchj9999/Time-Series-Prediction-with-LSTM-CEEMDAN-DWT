{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079edede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import yfinance as yf\n",
    "import math\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhht.visualization import plot_imfs\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime,timedelta\n",
    "from pyhht.emd import EMD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from matplotlib import gridspec\n",
    "import pywt\n",
    "from pywt import wavedec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066aa65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQL:\n",
    "    def __init__(self):\n",
    "        super(MySQL, self).__init__()\n",
    "\n",
    "        self.connection = pymysql.connect(\n",
    "            host=\"\",\n",
    "            user=\"\",\n",
    "            password=\"\",\n",
    "            db=\"\",\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def connect(self, host, user, password, db):\n",
    "        self.connection = pymysql.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            db=db,\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def reconnect(self, DB_CONFIG):\n",
    "        self.connection = pymysql.connect(\n",
    "            host=DB_CONFIG['host'],\n",
    "            user=DB_CONFIG['user'],\n",
    "            password=DB_CONFIG['password'],\n",
    "            db=DB_CONFIG['db'],\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def execute(self, sql):\n",
    "        connection = self.connection\n",
    "        cursor = connection.cursor()\n",
    "        result = cursor.execute(sql)\n",
    "        connection.commit()\n",
    "        response = {\n",
    "            'result': result,\n",
    "            'sn': cursor.lastrowid\n",
    "        }\n",
    "\n",
    "        return response\n",
    "\n",
    "    def query(self, state):\n",
    "        connection = self.connection\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(state)\n",
    "            result = cursor.fetchall()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def ping(self):\n",
    "        self.connection.ping(reconnect=True)\n",
    "\n",
    "    def close(self):\n",
    "        self.connection.close()\n",
    "#整段時間區間\n",
    "train_begin_date = '2019-01-01'\n",
    "train_end_date = '2021-01-01'\n",
    "\n",
    "predict_begin_date = '2021-05-01'\n",
    "predict_end_date = '2021-05-31'\n",
    "\n",
    "# sql = \"SELECT * from demand order by dateㄍtime desc limit 30000\"\n",
    "sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(train_begin_date, predict_end_date)\n",
    "dbh = MySQL()\n",
    "all_data = dbh.query(sql)\n",
    "train_sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(train_begin_date, train_end_date)\n",
    "train_data = dbh.query(train_sql)\n",
    "predict_sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(predict_begin_date, predict_end_date)\n",
    "predict_data = dbh.query(predict_sql)\n",
    "dbh.close()\n",
    "all_df = pd.DataFrame(all_data)\n",
    "all_df = all_df.set_index('datetime')\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df = train_df.set_index('datetime')\n",
    "predict_df = pd.DataFrame(predict_data)\n",
    "predict_df = predict_df.set_index('datetime')\n",
    "# test_df = test_df.set_index('sn')\n",
    "# predict_df\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_df)\n",
    "# plt.plot(predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2bcaa4",
   "metadata": {},
   "source": [
    "# 將已蒐集的訓練集資料先進行分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5127f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet='Haar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練集的小波轉換\n",
    "train = train_df['demand_quarter']\n",
    "train_coefficients = pywt.wavedec(train, wavelet, level = 2)\n",
    "# max_level_train = pywt.swt_max_level(len(train))\n",
    "# train_coefficients = pywt.swt(train, 'db10', level=3)\n",
    "len(train_coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ca7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73395fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_coefficients[0])\n",
    "plt.plot(train_coefficients[1])\n",
    "plt.plot(train_coefficients[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試集的小波轉換\n",
    "test = predict_df['demand_quarter']\n",
    "test_coefficients = pywt.wavedec(test, wavelet, level =2)\n",
    "# max_level_train = pywt.swt_max_level(len(train))\n",
    "# train_coefficients = pywt.swt(train, 'db10', level=3)\n",
    "len(test_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# plt.xlim([600,900])\n",
    "plt.plot(train_coefficients[0])\n",
    "\n",
    "plt.plot(test_coefficients[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f41d1f",
   "metadata": {},
   "source": [
    "# 預訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSlidingWindow(dataset,windowSize):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(dataset)-windowSize):\n",
    "        x_train.append(dataset[i:i+windowSize])\n",
    "        y_train.append(dataset[i+windowSize])\n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acedc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(x, y,timestep,i,batch_size,epochs):\n",
    "#     batch_size = len(x)/50\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    y_temp = np.concatenate([np.array(x[-timestep:]).flatten(), np.array(y).flatten()], axis=0)\n",
    "    train_scaled_data = scaler.fit_transform(x.reshape(-1,1))\n",
    "    test_scaled_data = scaler.fit_transform(y_temp.reshape(-1,1))\n",
    "    \n",
    "    x_train,y_train = createSlidingWindow(train_scaled_data,timestep)\n",
    "    x_test,y_test = createSlidingWindow(test_scaled_data,timestep)\n",
    "    print(len(y_test))\n",
    "    print(len(x_test))\n",
    "    #Build LSTM model\n",
    "    model=Sequential()\n",
    "    #Add first layer to model\n",
    "    model.add(LSTM(32, return_sequences=False, input_shape=(timestep,x_train.shape[2])))\n",
    "    #Add second layer to model\n",
    "    # model.add(LSTM(4, return_sequences=False))\n",
    "    # #Add Dense Layer to model with 25 neurons\n",
    "    # model.add(Dense(4))\n",
    "    #Add Dense Layer to model with 1 neuron\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics = ['accuracy'],run_eagerly=True)\n",
    "    model.summary()\n",
    "    history = model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs)\n",
    "    print(x_test)\n",
    "    test_predict = model.predict(x_test)\n",
    "    predict_Close = scaler.inverse_transform(test_predict)\n",
    "    y_test_true = scaler.inverse_transform(y_test)\n",
    "    LSTM_R2 = r2_score(y_test_true,predict_Close)\n",
    "    LSTM_MSE = mean_squared_error(y_test_true,predict_Close)\n",
    "    LSTM_MAE = mean_absolute_error(y_test_true,predict_Close)\n",
    "    print(\"LSTM_R2=\",LSTM_R2)\n",
    "    print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "    print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "    print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "    plt.figure(figsize=(10 ,5))\n",
    "    plt.title(\"sliding_window_size:{}\".format(timestep))\n",
    "    plt.plot(y_test_true)\n",
    "    plt.plot(predict_Close,c='g')\n",
    "    plt.legend(['data', 'LSTM_prediction'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    plt.plot(loss, label='loss')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    \n",
    "    simple_LSTM_modal_save_path = './model/DWT_simple-LSTM-model-result-{}-{}.h5'.format(i,timestep)\n",
    "    model.save(simple_LSTM_modal_save_path)  # creates a HDF5 file 'my_model.h5'\n",
    "#     filters = model.layers[0].get_weights()\n",
    "#     print(filters)\n",
    "    \n",
    "    return predict_Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_R2 = []\n",
    "LSTM_MSE = []\n",
    "LSTM_MAE = []\n",
    "LSTM_MRE = []\n",
    "LSTM_MAPE = []\n",
    "for look_back in range(48,288,48):\n",
    "    result_1 = LSTM_model(train_coefficients[0],test_coefficients[0],look_back,1,batch_size,epochs)\n",
    "    result_2 = LSTM_model(train_coefficients[1],test_coefficients[1],look_back,2,batch_size,epochs)\n",
    "    result_3 = LSTM_model(train_coefficients[2],test_coefficients[2],look_back,3,batch_size,epochs)\n",
    "\n",
    "    final_result = []\n",
    "    final_result.append(result_1.ravel())\n",
    "    final_result.append(result_2.ravel())\n",
    "    final_result.append(result_3.ravel())\n",
    "    \n",
    "    updated_original = pywt.waverec(final_result, wavelet)\n",
    "    \n",
    "    k = test.tolist()\n",
    "    r = updated_original[:2873]\n",
    "    LSTM_R2.append(r2_score(k,r))\n",
    "    LSTM_MSE.append(mean_squared_error(k,r))\n",
    "    LSTM_MAE.append(mean_absolute_error(k,r))\n",
    "    LSTM_MRE.append(np.mean(np.abs((k - r) / k)) * 100)\n",
    "    LSTM_MAPE.append((abs(r-k)/k).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LSTM_R2,LSTM_MSE,LSTM_MAE,LSTM_MRE,LSTM_MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = LSTM_model(train_coefficients[0],test_coefficients[0],timestamp,1,batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = LSTM_model(train_coefficients[1],test_coefficients[1],timestamp,2,batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3 = LSTM_model(train_coefficients[2],test_coefficients[2],timestamp,3,batch_size,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3_zero = []\n",
    "for i in range(len(result_3)):\n",
    "    result_3_zero.append([0])\n",
    "result_3_zero = np.array(result_3_zero)\n",
    "result_3_zero\n",
    "\n",
    "result_2_zero = []\n",
    "for i in range(len(result_2)):\n",
    "    result_2_zero.append([0])\n",
    "result_2_zero = np.array(result_2_zero)\n",
    "result_2_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = []\n",
    "final_result.append(result_1.ravel())\n",
    "final_result.append(result_2.ravel())\n",
    "final_result.append(result_3_zero.ravel())\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e01528",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_original = pywt.waverec(final_result, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdae111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "\n",
    "k = test.tolist()\n",
    "r = updated_original[:2873]\n",
    "\n",
    "LSTM_R2 = r2_score(test.tolist(),updated_original[:2873])\n",
    "LSTM_MSE = mean_squared_error(test.tolist(),updated_original[:2873])\n",
    "LSTM_MAE = mean_absolute_error(test.tolist(),updated_original[:2873])\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "\n",
    "plt.xlim([200,500])\n",
    "plt.ylabel(\"demand\")\n",
    "plt.xlabel(\"minutes\")\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)\n",
    "\n",
    "plt.plot(test.tolist())\n",
    "plt.plot(updated_original,c='orange')\n",
    "plt.legend(['data', 'DWT_LSTM_prediction'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec64bda",
   "metadata": {},
   "source": [
    "# 抓新資料少量分解更新子訊號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取一段時間的電力資料，傳給DWT_decompose()\n",
    "def take_latest_several_data(end_date):\n",
    "\n",
    "    conn  =  pymysql.connect ( host = '' ,  user = '' ,  passwd = \"\" ,  db = '' ) \n",
    "    cur  =  conn.cursor() \n",
    "    select_sql = '''SELECT `datetime`, `demand_quarter`\n",
    "                    FROM `demand_with_weather_data`\n",
    "                    WHERE `datetime` < '{}'\n",
    "                    ORDER BY `datetime` DESC LIMIT {} '''.format(end_date,96)\n",
    "    result_object = cur.execute(select_sql)\n",
    "    results_values_list = cur.fetchall()\n",
    "    result_key_list = [i[0] for i in cur.description]\n",
    "\n",
    "    reframed = pd.DataFrame(results_values_list)\n",
    "    #         print(reframed)\n",
    "    reframed.columns = result_key_list\n",
    "    timestamp = pd.to_datetime(reframed.datetime, infer_datetime_format=True).values\n",
    "    reframed['timestamp'] = timestamp.tolist()\n",
    "    reframed = reframed.set_index('datetime')\n",
    "    cur.close () \n",
    "    conn.close()\n",
    "    reframed['demand_quarter'] = reframed['demand_quarter'].replace('', np.nan)\n",
    "    reframed['demand_quarter'] = reframed['demand_quarter'].astype(float) \n",
    "    electricity_new_data_df = reframed\n",
    "    electricity_new_data_df = electricity_new_data_df.drop('timestamp', axis=1)\n",
    "    electricity_new_data = electricity_new_data_df['demand_quarter'].to_list()\n",
    "    return  electricity_new_data_df[:96],list(reversed(electricity_new_data[:96]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8777cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = take_latest_several_data('2021-01-02 00:45:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DWT_decompose(coeff_num,old_data_list, end_date, wavelet, level):\n",
    "    financial_new_data_df,financial_new_data = take_latest_several_data(end_date)\n",
    "    print(financial_new_data)\n",
    "    new_data_coeff = pywt.wavedec(financial_new_data, wavelet, level=level)\n",
    "    print(new_data_coeff)\n",
    "    \n",
    "    if coeff_num == 1:\n",
    "        old_data_list[0] = np.append(old_data_list[0],new_data_coeff[0])\n",
    "    elif coeff_num == 2:\n",
    "        old_data_list[1] = np.append(old_data_list[1],new_data_coeff[1])\n",
    "    elif coeff_num == 3:\n",
    "        old_data_list[2] = np.append(old_data_list[2],new_data_coeff[2])\n",
    "#     print(new_data_coeff)\n",
    "    return old_data_list,new_data_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a9eba",
   "metadata": {},
   "source": [
    "# 增量預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multistep(model, input_data, n_steps_out):\n",
    "    predictions = []\n",
    "    current_input = input_data\n",
    "#     scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    for _ in range(n_steps_out):\n",
    "        prediction = model.predict(current_input)\n",
    "#         print('*******************',prediction)\n",
    "#         predict_Close = scaler.inverse_transform(prediction[0][0])\n",
    "        predictions.append(prediction)\n",
    "#         print('++++++++++++++++++++',current_input)\n",
    "        current_input = np.append(current_input[0:, 0:], np.expand_dims(prediction, axis=1), axis=1)\n",
    "#         print('--------------------',current_input)\n",
    "    return np.array(predictions)\n",
    "#\n",
    "# predict multistep ver.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d492153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_electricity(coeff,coeff_num, model_path,old_data_list,date_range_list,wavelet):\n",
    "\n",
    "    window_size = 96\n",
    "    feature_len = 1\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    test = np.array(coeff[-(window_size+1):])\n",
    "    test = test[::-1]\n",
    "#     print(test)\n",
    "#     train_scaled_data = scaler.fit_transform(np.array(reframed_supervised['Close_^TWII(t)']).reshape(-1,1))\n",
    "    test_scaled_data = scaler.fit_transform(test.reshape(-1,1))\n",
    "#     print(len(test_scaled_data))\n",
    "    x_test,y_test = createSlidingWindow(test_scaled_data,window_size)\n",
    "    vanilla_model = load_model(model_path)\n",
    "    final_predict = []\n",
    "    if coeff_num == 3: \n",
    "        even_test_scaled_data = []\n",
    "        odd_test_scaled_data = []\n",
    "        even_test_scaled_data = test_scaled_data[::2]\n",
    "        \n",
    "#         print(even_test_scaled_data)\n",
    "        test_predict = vanilla_model.predict(test_scaled_data)\n",
    "        predict_Close = scaler.inverse_transform(test_predict)\n",
    "        final_predict.append(predict_Close[0][0])\n",
    "\n",
    "#         print(coeff)\n",
    "        multi_predict = coeff\n",
    "        multi_predict = np.append(multi_predict,predict_Close[0][0])\n",
    "#         print('-------------------',multi_predict[-10:])\n",
    "#         for i in range(1,int(len(test_scaled_data)/2)+1,2):\n",
    "        odd_test_scaled_data = test_scaled_data[1::2]\n",
    "        \n",
    "        test = np.array(multi_predict[-(window_size+1):])\n",
    "        test = test[::-1]\n",
    "        test_scaled_data = scaler.fit_transform(test.reshape(-1,1))\n",
    "#         x_test,y_test = createSlidingWindow(test_scaled_data,window_size)\n",
    "        test_predict = vanilla_model.predict(test_scaled_data)\n",
    "        predict_Close = scaler.inverse_transform(test_predict)\n",
    "        final_predict.append(predict_Close[0][0])\n",
    "    else:\n",
    "#         print('原始: ',x_test)\n",
    "        test_predict = vanilla_model.predict(test_scaled_data)\n",
    "#         print(\"預測: \",test_predict)\n",
    "        predict_Close = scaler.inverse_transform(test_predict)\n",
    "        final_predict.append(predict_Close[0][0])\n",
    "\n",
    "    data_list,new_data_coeff = DWT_decompose(coeff_num,old_data_list,date_range_list,wavelet,2)\n",
    "#     print(data_list[2][-10:])\n",
    "    test_new = np.array(data_list[coeff_num-1])\n",
    "    test_new = test_new[::-1]\n",
    "#     print('--------',len(test_new),test_new)\n",
    "    test_scaled_data_new = scaler.fit_transform(test_new.reshape(-1,1))\n",
    "#     print('--------',len(test_scaled_data_new[:window_size,:]),test_scaled_data_new[:window_size,:])\n",
    "    x_test_new,y_test_new = createSlidingWindow(test_scaled_data_new[:(window_size+1),:],window_size)\n",
    "    vanilla_model.compile(loss='mse', optimizer='Adam') \n",
    "#     print('-----',y_test_new)\n",
    "    vanilla_model_history = vanilla_model.fit(test_scaled_data_new[1:(window_size+1),:],test_scaled_data_new[:window_size,:],batch_size=60,epochs=100)\n",
    "#         all_update_features, update_labels)\n",
    "\n",
    "    vanilla_model.save(model_path) \n",
    "    del vanilla_model\n",
    "    print('+++',final_predict)\n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d195b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date_range(old_data_list,date_range_list,wavelet):\n",
    "    predict_list = []\n",
    "    execute_time_list = []\n",
    "    all_time_start = time.time()\n",
    "    print(date_range_list)\n",
    "#     for i in range(len(date_range_list)):\n",
    "    print(i,date_range_list)\n",
    "    start = time.time()\n",
    "#     data_list,new_data_coeff = DWT_decompose(old_data_list,date_range_list,wavelet,2)\n",
    "\n",
    "\n",
    "#     new_data_coeff = pywt.wavedec(old_data_list, wavelet, level=2)\n",
    "    coefficient1_result = predict_electricity(old_data_list[0],1,'./model/DWT_simple-LSTM-model-result-1-Copy1.h5',old_data_list,date_range_list,wavelet)\n",
    "    coefficient2_result = predict_electricity(old_data_list[1],2,'./model/DWT_simple-LSTM-model-result-2-Copy1.h5',old_data_list,date_range_list,wavelet)\n",
    "    coefficient3_result = predict_electricity(old_data_list[2],3,'./model/DWT_simple-LSTM-model-result-3-Copy1.h5',old_data_list,date_range_list,wavelet)\n",
    "    \n",
    "\n",
    "#     print(coefficient1_result)\n",
    "    \n",
    "    predict_coeff = []\n",
    "    temp = []\n",
    "    predict_coeff.append(np.array(coefficient1_result))\n",
    "    predict_coeff.append(np.array(coefficient2_result))\n",
    "#     temp.append(np.array(coefficient3_result).ravel())\n",
    "#     temp.append(np.array(coefficient3_result).ravel())\n",
    "    predict_coeff.append(np.array(coefficient3_result))\n",
    "#     predict_coeff.append(coefficient4_result[0].ravel())\n",
    "#     predict_coeff.append(np.array(temp).ravel())\n",
    "#     predict_coeff.append(np.array(0).ravel())\n",
    "#     predict_coeff.append(np.array(0).ravel())\n",
    "#     print(predict_coeff)\n",
    "    \n",
    "    predict_result = pywt.waverec(predict_coeff, wavelet)\n",
    "    predict_list.append(predict_result)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    execute_time_list.append(end - start)\n",
    "    all_time_end = time.time()\n",
    "    print(\"執行時間：%f 秒\" % (all_time_end - all_time_start))\n",
    "    return predict_list,coefficient1_result,coefficient2_result,coefficient3_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74617a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_1 = pd.date_range(start='2021-05-01 00:00:00', end='2021-05-03 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71938505",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_2 = pd.date_range(start='2021-05-04 00:00:00', end='2021-05-06 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_3 = pd.date_range(start='2021-05-07 00:00:00', end='2021-05-09 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_test384 = pd.date_range(start='2021-05-01 00:00:00', end='2021-05-15 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(date_range_list_test384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coefficient_append = train_coefficients\n",
    "decompose_start = time.time()\n",
    "for i in range(int(len(date_range_list_test384)/4)):\n",
    "#     print(date_range_list_1[i])\n",
    "    data_list,new_data_coeff = DWT_decompose(1,train_coefficient_append,date_range_list_test384[4*i+3],wavelet,2)\n",
    "decompose_end = time.time()\n",
    "decompose_time = decompose_end - decompose_start\n",
    "print(\"分解時間:%f 秒\" % decompose_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a792a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coefficient_append = train_coefficients\n",
    "decompose_start = time.time()\n",
    "for i in range(int(len(date_range_list_test384)/384)):\n",
    "#     print(date_range_list_1[i])\n",
    "    data_list,new_data_coeff = DWT_decompose(1,train_coefficient_append,date_range_list_test384[384*i+3],wavelet,2)\n",
    "decompose_end = time.time()\n",
    "decompose_time = decompose_end - decompose_start\n",
    "print(\"分解時間:%f 秒\" % decompose_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_1 = []\n",
    "coeff_predict_list_1 = []\n",
    "coeff_1_predict_list_1 = []\n",
    "coeff_2_predict_list_1 = []\n",
    "coeff_3_predict_list_1 = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train_coefficients\n",
    "for i in range(int(len(date_range_list_1)/4)):\n",
    "#     print(date_range_list_1[i])\n",
    "    predict_value,coeff1,coeff2,coeff3 = predict_date_range(train_coefficients,date_range_list_1[4*i+3],wavelet)\n",
    "    predict_list_1.append(predict_value)\n",
    "    coeff_1_predict_list_1.append(coeff1)\n",
    "    coeff_2_predict_list_1.append(coeff2)\n",
    "    coeff_3_predict_list_1.append(coeff3)\n",
    "#     print(predict_list)\n",
    "\n",
    "#     print('--------------',train_coefficients[2][-30:])\n",
    "#     renew_model(1,'./model/DWT_simple-LSTM-model-result-1-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(2,'./model/DWT_simple-LSTM-model-result-2-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(3,'./model/DWT_simple-LSTM-model-result-3-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "coeff_predict_list_1.append(coeff_1_predict_list_1)\n",
    "coeff_predict_list_1.append(coeff_2_predict_list_1)\n",
    "coeff_predict_list_1.append(coeff_3_predict_list_1)\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_s1 = []\n",
    "coeff_predict_list_s1 = []\n",
    "coeff_1_predict_list_s1 = []\n",
    "coeff_2_predict_list_s1 = []\n",
    "coeff_3_predict_list_s1 = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train_coefficients\n",
    "for i in range(int(len(date_range_list_1)/4)):\n",
    "#     print(date_range_list_1[i])\n",
    "    predict_value,coeff1,coeff2,coeff3 = predict_date_range(train_coefficients,date_range_list_1[4*i+3],wavelet)\n",
    "    predict_list_s1.append(predict_value)\n",
    "    coeff_1_predict_list_s1.append(coeff1)\n",
    "    coeff_2_predict_list_s1.append(coeff2)\n",
    "    coeff_3_predict_list_s1.append(coeff3)\n",
    "#     print(predict_list)\n",
    "\n",
    "#     print('--------------',train_coefficients[2][-30:])\n",
    "#     renew_model(1,'./model/DWT_simple-LSTM-model-result-1-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(2,'./model/DWT_simple-LSTM-model-result-2-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(3,'./model/DWT_simple-LSTM-model-result-3-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "coeff_predict_list_s1.append(coeff_1_predict_list_s1)\n",
    "coeff_predict_list_s1.append(coeff_2_predict_list_s1)\n",
    "coeff_predict_list_s1.append(coeff_3_predict_list_s1)\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0830c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_2 = []\n",
    "coeff_predict_list_2 = []\n",
    "coeff_1_predict_list_2 = []\n",
    "coeff_2_predict_list_2 = []\n",
    "coeff_3_predict_list_2 = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train_coefficients\n",
    "for i in range(int(len(date_range_list_2)/4)):\n",
    "#     print(date_range_list_1[i])\n",
    "    predict_value,coeff1,coeff2,coeff3 = predict_date_range(train_coefficients,date_range_list_2[4*i+3],wavelet)\n",
    "    predict_list_2.append(predict_value)\n",
    "    coeff_1_predict_list_2.append(coeff1)\n",
    "    coeff_2_predict_list_2.append(coeff2)\n",
    "    coeff_3_predict_list_2.append(coeff3)\n",
    "#     print(predict_list)\n",
    "\n",
    "#     print('--------------',train_coefficients[2][-30:])\n",
    "#     renew_model(1,'./model/DWT_simple-LSTM-model-result-1-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(2,'./model/DWT_simple-LSTM-model-result-2-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(3,'./model/DWT_simple-LSTM-model-result-3-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "coeff_predict_list_2.append(coeff_1_predict_list_2)\n",
    "coeff_predict_list_2.append(coeff_2_predict_list_2)\n",
    "coeff_predict_list_2.append(coeff_3_predict_list_2)\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14946dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_3 = []\n",
    "coeff_predict_list_3 = []\n",
    "coeff_1_predict_list_3 = []\n",
    "coeff_2_predict_list_3 = []\n",
    "coeff_3_predict_list_3 = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train_coefficients\n",
    "for i in range(int(len(date_range_list_3)/4)):\n",
    "#     print(date_range_list_1[i])\n",
    "    predict_value,coeff1,coeff2,coeff3 = predict_date_range(train_coefficients,date_range_list_3[4*i+3],wavelet)\n",
    "    predict_list_3.append(predict_value)\n",
    "    coeff_1_predict_list_3.append(coeff1)\n",
    "    coeff_2_predict_list_3.append(coeff2)\n",
    "    coeff_3_predict_list_3.append(coeff3)\n",
    "#     print(predict_list)\n",
    "\n",
    "#     print('--------------',train_coefficients[2][-30:])\n",
    "#     renew_model(1,'./model/DWT_simple-LSTM-model-result-1-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(2,'./model/DWT_simple-LSTM-model-result-2-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "#     renew_model(3,'./model/DWT_simple-LSTM-model-result-3-Copy1.h5',train_coefficients,date_range_list_1[4*i],wavelet)\n",
    "coeff_predict_list_3.append(coeff_1_predict_list_3)\n",
    "coeff_predict_list_3.append(coeff_2_predict_list_3)\n",
    "coeff_predict_list_3.append(coeff_3_predict_list_3)\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_1 = np.array(predict_list_1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b35d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_s1 = np.array(predict_list_s1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_2 = np.array(predict_list_2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b60b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_3 = np.array(predict_list_3).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b257b",
   "metadata": {},
   "source": [
    "# 比較實際值與預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取真實電力資料的dataframe\n",
    "def get_true_value(start_day,end_day):\n",
    "    conn  =  pymysql.connect ( host = '' ,  user = '' ,  passwd = \"\" ,  db = '' ) \n",
    "    cur  =  conn.cursor() \n",
    "    select_sql = '''SELECT `datetime`, `demand_quarter`\n",
    "                    FROM `demand_with_weather_data`\n",
    "                    WHERE `datetime` >= '{}' AND `datetime` <= '{}' '''.format(start_day, end_day)\n",
    "    result_object = cur.execute(select_sql)\n",
    "    results_values_list = cur.fetchall()\n",
    "    result_key_list = [i[0] for i in cur.description]\n",
    "    true_day_value = pd.DataFrame(results_values_list)\n",
    "    true_day_value.columns = result_key_list\n",
    "    true_day_value = true_day_value.set_index('datetime')\n",
    "    cur.close () \n",
    "    conn.close()\n",
    "\n",
    "    true_day_value['demand_quarter'] = true_day_value['demand_quarter'].replace('', np.nan)\n",
    "    true_day_value['demand_quarter'] = true_day_value['demand_quarter'].astype(float)  \n",
    "    return true_day_value\n",
    "    # datelist = true_day_value.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將真實資料與預測值合併成一個dataframe\n",
    "def concat_true_and_predict_value(start_day, end_day,date_range_list, predict_list):\n",
    "    true_day_value = get_true_value(start_day,end_day)\n",
    "#     predict_datelist = datelist(start_day,end_day)\n",
    "    predict_datelist = date_range_list\n",
    "    predict_df = pd.DataFrame({'datetime': predict_datelist[:960], 'predict': predict_list})\n",
    "#     execute_time_df = pd.DataFrame({'datetime': predict_datelist, 'execute_time': execute_list})\n",
    "    predict_df = predict_df.set_index('datetime')\n",
    "#     execute_time_df = execute_time_df.set_index('datetime')\n",
    "    merged_df = pd.concat([true_day_value, predict_df], axis=1)\n",
    "#     merged_df = pd.concat([merged_df, execute_time_df], axis=1)\n",
    "    merged_df = merged_df.dropna()\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02390aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(date_range_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_1 = concat_true_and_predict_value('2021-05-01 00:00:00','2021-05-03 23:45:00',date_range_list_1,predict_list_1)\n",
    "concat_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_s1 = concat_true_and_predict_value('2021-05-01 00:00:00','2021-05-03 23:45:00',date_range_list_1,predict_list_s1)\n",
    "concat_df_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window denoise\n",
    "result_s3_zero = []\n",
    "for i in range(2*len(coeff_3_predict_list_s1)):\n",
    "    result_s3_zero.append([0])\n",
    "result_s3_zero = np.array(result_s3_zero)\n",
    "# print(len(coeff_3_predict_list_1))\n",
    "\n",
    "result_s2_zero = []\n",
    "for i in range(len(coeff_2_predict_list_s1)):\n",
    "    result_s2_zero.append([0])\n",
    "result_s2_zero = np.array(result_s2_zero)\n",
    "# print(len(coeff_2_predict_list_1))\n",
    "\n",
    "thr = 10.3654\n",
    "\n",
    "thress2 = pywt.threshold(coeff_2_predict_list_s1, thr, 'hard')\n",
    "thress3 = pywt.threshold(coeff_3_predict_list_s1, thr, 'hard')\n",
    "\n",
    "final_result_s = []\n",
    "final_result_s.append(np.array(coeff_1_predict_list_s1).ravel())\n",
    "final_result_s.append(np.array(thress2).ravel())\n",
    "final_result_s.append(np.array(thress3).ravel())\n",
    "# print(final_result)\n",
    "updated_original_s = pywt.waverec(final_result_s, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3_zero = []\n",
    "for i in range(2*len(coeff_3_predict_list_1)):\n",
    "    result_3_zero.append([0])\n",
    "result_3_zero = np.array(result_3_zero)\n",
    "# print(len(coeff_3_predict_list_1))\n",
    "\n",
    "result_2_zero = []\n",
    "for i in range(len(coeff_2_predict_list_1)):\n",
    "    result_2_zero.append([0])\n",
    "result_2_zero = np.array(result_2_zero)\n",
    "# print(len(coeff_2_predict_list_1))\n",
    "\n",
    "thr = 10.3654\n",
    "\n",
    "thres2 = pywt.threshold(coeff_2_predict_list_1, thr, 'hard')\n",
    "thres3 = pywt.threshold(coeff_3_predict_list_1, thr, 'hard')\n",
    "\n",
    "final_result = []\n",
    "final_result.append(np.array(coeff_1_predict_list_1).ravel())\n",
    "final_result.append(np.array(thres2).ravel())\n",
    "final_result.append(np.array(thres3).ravel())\n",
    "# print(final_result)\n",
    "updated_original = pywt.waverec(final_result, wavelet)\n",
    "\n",
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])\n",
    "# plt.xlim([0,100])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_1['demand_quarter'].to_list())\n",
    "plt.plot(updated_original_s,c='violet')\n",
    "plt.plot(updated_original,c='orange')\n",
    "\n",
    "plt.legend(['data', 'DWT_prediction','DWT_prediction(incremental)'], loc='upper right')\n",
    "plt.ylim([100,350])\n",
    "plt.show()\n",
    "\n",
    "k = concat_df_1['demand_quarter']\n",
    "r = updated_original_s\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_1['demand_quarter'],updated_original_s)\n",
    "LSTM_MSE = mean_squared_error(concat_df_1['demand_quarter'],updated_original_s)\n",
    "LSTM_MAE = mean_absolute_error(concat_df_1['demand_quarter'],updated_original_s)\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_2_predict_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.concat([concat_df_1, pd.DataFrame(updated_original)])\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])464M0-LK83Q-0Y9B8\n",
    "# plt.xlim([0,100])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_1['demand_quarter'].to_list())\n",
    "plt.plot(concat_df_1['predict'].to_list(),c='orange')\n",
    "# plt.xlim([100,300])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MSE = mean_squared_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MAE = mean_absolute_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_2 = concat_true_and_predict_value('2021-05-04 00:00:00','2021-05-06 23:45:00',date_range_list_2,predict_list_2)\n",
    "concat_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3_zero = []\n",
    "for i in range(2*len(coeff_3_predict_list_2)):\n",
    "    result_3_zero.append([0])\n",
    "result_3_zero = np.array(result_3_zero)\n",
    "# print(len(coeff_3_predict_list_1))\n",
    "\n",
    "result_2_zero = []\n",
    "for i in range(len(coeff_2_predict_list_2)):\n",
    "    result_2_zero.append([0])\n",
    "result_2_zero = np.array(result_2_zero)\n",
    "# print(len(coeff_2_predict_list_1))\n",
    "\n",
    "\n",
    "thr = 3.3654\n",
    "thres2 = pywt.threshold(coeff_2_predict_list_2, thr, 'hard')\n",
    "thres3 = pywt.threshold(coeff_3_predict_list_2, thr, 'hard')\n",
    "\n",
    "final_result = []\n",
    "final_result.append(np.array(coeff_1_predict_list_2).ravel())\n",
    "final_result.append(np.array(thres2).ravel())\n",
    "final_result.append(np.array(thres3).ravel())\n",
    "# print(final_result)\n",
    "updated_original = pywt.waverec(final_result, wavelet)\n",
    "\n",
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])\n",
    "# plt.xlim([0,100])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_2['demand_quarter'].to_list())\n",
    "plt.plot(updated_original,c='orange')\n",
    "plt.legend(['data', 'DWT_LSTM_prediction'], loc='upper right')\n",
    "plt.ylim([100,500])\n",
    "# plt.xlim([100,150])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_2['demand_quarter'],updated_original)\n",
    "LSTM_MSE = mean_squared_error(concat_df_2['demand_quarter'],updated_original)\n",
    "LSTM_MAE = mean_absolute_error(concat_df_2['demand_quarter'],updated_original)\n",
    "k = concat_df_2['demand_quarter']\n",
    "r = updated_original\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(updated_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])464M0-LK83Q-0Y9B8\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_2['demand_quarter'].to_list())\n",
    "plt.plot(concat_df_2['predict'].to_list(),c='orange')\n",
    "# plt.xlim([100,300])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_2['demand_quarter'],concat_df_2['predict'])\n",
    "LSTM_MSE = mean_squared_error(concat_df_2['demand_quarter'],concat_df_2['predict'])\n",
    "LSTM_MAE = mean_absolute_error(concat_df_2['demand_quarter'],concat_df_2['predict'])\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_3 = concat_true_and_predict_value('2021-05-07 00:00:00','2021-05-09 23:45:00',date_range_list_3,predict_list_3)\n",
    "concat_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3_zero = []\n",
    "for i in range(2*len(coeff_3_predict_list_3)):\n",
    "    result_3_zero.append([0])\n",
    "result_3_zero = np.array(result_3_zero)\n",
    "# print(len(coeff_3_predict_list_1))\n",
    "\n",
    "result_2_zero = []\n",
    "for i in range(len(coeff_2_predict_list_3)):\n",
    "    result_2_zero.append([0])\n",
    "result_2_zero = np.array(result_2_zero)\n",
    "# print(len(coeff_2_predict_list_1))\n",
    "\n",
    "\n",
    "\n",
    "thr = 5.3654\n",
    "thres2 = pywt.threshold(coeff_2_predict_list_3, thr, 'hard')\n",
    "thres3 = pywt.threshold(coeff_3_predict_list_3, thr, 'hard')\n",
    "\n",
    "final_result = []\n",
    "final_result.append(np.array(coeff_1_predict_list_3).ravel())\n",
    "final_result.append(np.array(thres2).ravel())\n",
    "final_result.append(np.array(thres3).ravel())\n",
    "# print(final_result)\n",
    "updated_original = pywt.waverec(final_result, wavelet)\n",
    "\n",
    "plt.figure(figsize=(10 ,5))\n",
    "\n",
    "# plt.ylim([100,350])\n",
    "plt.plot(concat_df_3['demand_quarter'].to_list())\n",
    "plt.plot(updated_original,c='orange')\n",
    "plt.legend(['data', 'DWT_LSTM_prediction'], loc='upper right')\n",
    "# plt.xlim([100,300])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_3['demand_quarter'],updated_original)\n",
    "LSTM_MSE = mean_squared_error(concat_df_3['demand_quarter'],updated_original)\n",
    "LSTM_MAE = mean_absolute_error(concat_df_3['demand_quarter'],updated_original)\n",
    "k = concat_df_3['demand_quarter']\n",
    "r = updated_original\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_2_predict_list_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])464M0-LK83Q-0Y9B8\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_3['demand_quarter'].to_list())\n",
    "plt.plot(concat_df_3['predict'].to_list(),c='orange')\n",
    "# plt.xlim([0,100])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_3['demand_quarter'],concat_df_3['predict'])\n",
    "LSTM_MSE = mean_squared_error(concat_df_3['demand_quarter'],concat_df_3['predict'])\n",
    "LSTM_MAE = mean_absolute_error(concat_df_3['demand_quarter'],concat_df_3['predict'])\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ed473",
   "metadata": {},
   "source": [
    "# 訊號重建觀察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])464M0-LK83Q-0Y9B8\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_1['demand_quarter'].to_list())\n",
    "plt.plot(concat_df_1['predict'].to_list(),c='g')\n",
    "# plt.xlim([100,300])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MSE = mean_squared_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MAE = mean_absolute_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444df444",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_reconstruct = pywt.waverec(train_coefficients, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coeff_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa11b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_begin_t = '2021-05-01 00:00:00'\n",
    "train_end_t = '2021-05-04 23:45:00'\n",
    "\n",
    "\n",
    "conn  =  pymysql.connect ( host = '' ,  user = '' ,  passwd = \"\" ,  db = '' ) \n",
    "cur  =  conn.cursor() \n",
    "dbh = MySQL()\n",
    "train_sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` <= '{}'\n",
    "                ORDER BY `datetime` '''.format(train_begin_t, train_end_t)\n",
    "train_and_predict_data = dbh.query(train_sql)\n",
    "dbh.close()\n",
    "train_and_predict_df = pd.DataFrame(train_and_predict_data)\n",
    "train_and_predict_df = train_and_predict_df.set_index('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_and_predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練集的小波轉換\n",
    "train_rec = train_and_predict_df['demand_quarter']\n",
    "train_coefficientrec = pywt.wavedec(train_rec, wavelet, level = 2)\n",
    "# max_level_train = pywt.swt_max_level(len(train))\n",
    "# train_coefficients = pywt.swt(train, 'db10', level=3)\n",
    "len(train_coefficientrec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_predict_list = pywt.wavedec(concat_df_1['predict'].to_list(), 'db1')\n",
    "test_coeff_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_predict_list\n",
    "test_coeff_predict_list[-1] = np.zeros_like(test_coeff_predict_list[-1])\n",
    "test_coeff_predict_list[-2] = np.zeros_like(test_coeff_predict_list[-2])\n",
    "\n",
    "filtered_data_dwt=pywt.waverec(test_coeff_predict_list,'db1',mode='symmetric',axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_dwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7948740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from skimage import data, img_as_float\n",
    "from skimage.util import random_noise\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "sigma = 2\n",
    "# data_denoise = denoise_wavelet(np.array(decompose_data_1), multichannel=True, convert2ycbcr=True, method='BayesShrink', mode='soft', wavelet_levels=2, wavelet=wavelet)\n",
    "data_denoise = denoise_wavelet(np.array(coeff_predict_list[0]).ravel(), sigma=sigma, wavelet=wavelet, wavelet_levels=2)\n",
    "\n",
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.xlim([0,20])\n",
    "plt.plot(train_coefficientrec[0])\n",
    "plt.plot(data_denoise,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_denoise_list = []\n",
    "data_denoise_list.append(data_denoise)\n",
    "data_denoise1 = denoise_wavelet(np.array(coeff_predict_list[1]).ravel(), sigma=sigma, wavelet=wavelet, wavelet_levels=2)\n",
    "data_denoise_list.append(data_denoise1)\n",
    "data_denoise2 = denoise_wavelet(np.array(coeff_predict_list[2]).ravel(), sigma=sigma, wavelet=wavelet, wavelet_levels=2)\n",
    "data_denoise_list.append(data_denoise2)\n",
    "\n",
    "# print(data_denoise_list)\n",
    "data_denoise_rec = pywt.waverec(data_denoise_list, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61014586",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])464M0-LK83Q-0Y9B8\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(concat_df_1['demand_quarter'].to_list())\n",
    "plt.plot(data_denoise_rec,c='r')\n",
    "# plt.xlim([100,300])\n",
    "plt.show()\n",
    "\n",
    "LSTM_R2 = r2_score(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MSE = mean_squared_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "LSTM_MAE = mean_absolute_error(concat_df_1['demand_quarter'],concat_df_1['predict'])\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "plt.plot(train_coefficients[0])\n",
    "plt.plot(train_coefficientrec[0].tolist(),c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ded30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "plt.plot(train_coefficients[1][-240:])\n",
    "plt.plot(train_coefficientrec[1].tolist(),c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e326d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.plot(train_coefficients[2][1220:])\n",
    "plt.plot(train_coefficients[2][-144:])\n",
    "plt.plot(train_coefficientrec[2].tolist(),c='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "plt.plot(coeff_reconstruct[-288:])\n",
    "plt.plot(train_and_predict_df['demand_quarter'].tolist(),c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coeff_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_and_predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df922de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69344d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
