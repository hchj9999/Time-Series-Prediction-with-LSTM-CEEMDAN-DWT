{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "import pymysql.cursors\n",
    "import yfinance as yf\n",
    "import math\n",
    "from math import sqrt\n",
    "import pandas_datareader as web\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, BatchNormalization, TimeDistributed, Flatten, Bidirectional,Dropout, MultiHeadAttention\n",
    "from pyhht.visualization import plot_imfs\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime,timedelta\n",
    "from pyhht.emd import EMD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from attention import Attention\n",
    "from pyhht.emd import EMD\n",
    "from matplotlib import pyplot\n",
    "from pyhht.visualization import plot_imfs\n",
    "from PyEMD import CEEMDAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQL:\n",
    "    def __init__(self):\n",
    "        super(MySQL, self).__init__()\n",
    "\n",
    "        self.connection = pymysql.connect(\n",
    "            host=\"\",\n",
    "            user=\"\",\n",
    "            password=\"\",\n",
    "            db=\"\",\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def connect(self, host, user, password, db):\n",
    "        self.connection = pymysql.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            db=db,\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def reconnect(self, DB_CONFIG):\n",
    "        self.connection = pymysql.connect(\n",
    "            host=DB_CONFIG['host'],\n",
    "            user=DB_CONFIG['user'],\n",
    "            password=DB_CONFIG['password'],\n",
    "            db=DB_CONFIG['db'],\n",
    "            charset='utf8',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "\n",
    "    def execute(self, sql):\n",
    "        connection = self.connection\n",
    "        cursor = connection.cursor()\n",
    "        result = cursor.execute(sql)\n",
    "        connection.commit()\n",
    "        response = {\n",
    "            'result': result,\n",
    "            'sn': cursor.lastrowid\n",
    "        }\n",
    "\n",
    "        return response\n",
    "\n",
    "    def query(self, state):\n",
    "        connection = self.connection\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(state)\n",
    "            result = cursor.fetchall()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def ping(self):\n",
    "        self.connection.ping(reconnect=True)\n",
    "\n",
    "    def close(self):\n",
    "        self.connection.close()\n",
    "#整段時間區間\n",
    "train_begin_date = '2017-07-01'\n",
    "train_end_date = '2021-01-01'\n",
    "predict_begin_date = '2021-05-01'\n",
    "predict_end_date = '2021-05-31'\n",
    "\n",
    "# sql = \"SELECT * from demand order by dateㄍtime desc limit 30000\"\n",
    "sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(train_begin_date, predict_end_date)\n",
    "dbh = MySQL()\n",
    "all_data = dbh.query(sql)\n",
    "train_sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(train_begin_date, train_end_date)\n",
    "train_data = dbh.query(train_sql)\n",
    "predict_sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(predict_begin_date, predict_end_date)\n",
    "predict_data = dbh.query(predict_sql)\n",
    "dbh.close()\n",
    "all_df = pd.DataFrame(all_data)\n",
    "all_df = all_df.set_index('datetime')\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df = train_df.set_index('datetime')\n",
    "predict_df = pd.DataFrame(predict_data)\n",
    "predict_df = predict_df.set_index('datetime')\n",
    "# test_df = test_df.set_index('sn')\n",
    "# predict_df\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9214b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.array(train_df['demand_quarter'].astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(predict_df['demand_quarter'].astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfff5c8",
   "metadata": {},
   "source": [
    "# 預訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 96\n",
    "batch_size = 60\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87361c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSlidingWindow(dataset,windowSize):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(dataset)-windowSize):\n",
    "        x_train.append(dataset[i:i+windowSize])\n",
    "        y_train.append(dataset[i+windowSize])\n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd87e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(x_train, y_train,timestep):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_scaled_data = scaler.fit_transform(x_train.reshape(-1,1))\n",
    "    test_scaled_data = scaler.fit_transform(y_train.reshape(-1,1))\n",
    "    \n",
    "    x_train,y_train = createSlidingWindow(train_scaled_data,timestep)\n",
    "    x_test,y_test = createSlidingWindow(test_scaled_data,timestep)\n",
    "    \n",
    "#     #Build LSTM model\n",
    "    model=Sequential()\n",
    "    #Add first layer to model\n",
    "    model.add(LSTM(8, return_sequences=False, input_shape=(timestep,x_train.shape[2])))\n",
    "    #Add second layer to model\n",
    "    # model.add(LSTM(4, return_sequences=False))\n",
    "    # #Add Dense Layer to model with 25 neurons\n",
    "    # model.add(Dense(4))\n",
    "    #Add Dense Layer to model with 1 neuron\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    history = model.fit(x_train,y_train,batch_size=60,epochs=100)\n",
    "    test_predict = model.predict(x_test)\n",
    "    predict_Close = scaler.inverse_transform(test_predict)\n",
    "    y_test_true = scaler.inverse_transform(y_test)\n",
    "    LSTM_R2 = r2_score(y_test_true,predict_Close)\n",
    "    LSTM_MSE = mean_squared_error(y_test_true,predict_Close)\n",
    "    LSTM_MAE = mean_absolute_error(y_test_true,predict_Close)\n",
    "    print(\"LSTM_R2=\",LSTM_R2)\n",
    "    print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "    print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "    print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "    plt.figure(figsize=(10 ,5))\n",
    "    plt.title(\"sliding_window_size:{}\".format(timestep))\n",
    "    plt.plot(y_test_true)\n",
    "    plt.plot(predict_Close,c='g')\n",
    "    plt.legend(['data', 'LSTM_prediction'], loc='upper right')\n",
    "    plt.show()\n",
    "    simple_LSTM_modal_save_path = './model/univariate-LSTM-model-result.h5'\n",
    "    model.save(simple_LSTM_modal_save_path)  # creates a HDF5 file 'my_model.h5'\n",
    "    return predict_Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_scaled_data = scaler.fit_transform(train.reshape(-1,1))\n",
    "test_scaled_data = scaler.fit_transform(test.reshape(-1,1))\n",
    "    \n",
    "x_train,y_train = createSlidingWindow(train_scaled_data,96)\n",
    "x_test,y_test = createSlidingWindow(test_scaled_data,96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = LSTM_model(train,test,timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d1ea1",
   "metadata": {},
   "source": [
    "# 利用訓練好的模型對新資料進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3499c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_financial(coeff,model_path,old_data_list,date_range_list):\n",
    "\n",
    "    window_size = 96\n",
    "    feature_len = 1\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    test = np.array(coeff[-(window_size+1):])\n",
    "    test = test[::-1]\n",
    "    test = test.ravel()\n",
    "    test_scaled_data = scaler.fit_transform(test.reshape(-1,1))\n",
    "    x_test,y_test = createSlidingWindow(test_scaled_data,window_size)\n",
    "    vanilla_model = load_model(model_path)\n",
    "    test_predict = vanilla_model.predict(test_scaled_data)\n",
    "    predict_Close = scaler.inverse_transform(test_predict)\n",
    "    vanilla_model.compile(loss='mse', optimizer='Adam') \n",
    "    vanilla_model_history = vanilla_model.fit(x_test,y_test,batch_size=60,epochs=100)\n",
    "    vanilla_model.save(model_path) \n",
    "    del vanilla_model\n",
    "    print(predict_Close[0][0])\n",
    "    return predict_Close[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取日期範圍\n",
    "def datelist(start_date,end_date):\n",
    "    date_list = []\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')  # 起始日期\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')    # 结束日期\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ebeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取有資料的日期\n",
    "def date_with_value(start_day, end_day):\n",
    "    true_day_value = get_true_value(start_day,end_day)\n",
    "    predict_datelist = datelist(start_day,end_day)\n",
    "    predict_df = pd.DataFrame({'Date': predict_datelist})\n",
    "    execute_time_df = pd.DataFrame({'Date': predict_datelist})\n",
    "    predict_df = predict_df.set_index('Date')\n",
    "    execute_time_df = execute_time_df.set_index('Date')\n",
    "    merged_df = pd.concat([true_day_value, predict_df], axis=1)\n",
    "    merged_df = pd.concat([merged_df, execute_time_df], axis=1)\n",
    "    merged_df = merged_df.dropna()\n",
    "    merged_df = merged_df.reset_index()\n",
    "    date_range_list = merged_df['Date'].tolist()\n",
    "    return date_range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取真實金融資料的dataframe\n",
    "def get_true_value(start_day,end_day):\n",
    "\n",
    "    dataframe_Close = yf.download('^TWII',start=start_day,end=end_day)\n",
    "    dataframe_Close = dataframe_Close['Close']\n",
    "    dataframe_Close = pd.DataFrame(dataframe_Close)\n",
    "#     print(dataframe_Close)\n",
    "    dataframe_Close['Close'] = dataframe_Close['Close'].replace('', np.nan)\n",
    "    dataframe_Close['Close'] = dataframe_Close['Close'].astype(float)  \n",
    "    \n",
    "    dataframe_Close = dataframe_Close.reset_index()\n",
    "    dataframe_Close['Date'] = dataframe_Close['Date'].astype(\"string\")\n",
    "    dataframe_Close['Date'] = dataframe_Close['Date'].to_list()\n",
    "    return dataframe_Close\n",
    "    # datelist = true_day_value.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fac0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 第一個月\n",
    "start_day_1 = '2021-05-01 00:00:00'\n",
    "end_day_1 = '2021-05-04 00:00:00'\n",
    "# date_range_list_1 = datelist(start_day_1,end_day_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day_2 = '2021-05-04 00:00:00'\n",
    "end_day_2 = '2021-05-07 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day_3 = '2021-05-07 00:00:00'\n",
    "end_day_3 = '2021-05-10 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc317e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_1 = pd.date_range(start='2021-05-01 00:00:00', end='2021-05-03 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe41469",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_2 = pd.date_range(start='2021-05-04 00:00:00', end='2021-05-06 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_3 = pd.date_range(start='2021-05-07 00:00:00', end='2021-05-09 23:45:00', freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_list_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257038e6",
   "metadata": {},
   "source": [
    "# 執行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date_range(old_data_list,date_range_list):\n",
    "    predict_list = []\n",
    "    execute_time_list = []\n",
    "    all_time_start = time.time()\n",
    "    start = time.time()\n",
    "    predict_result = predict_financial(old_data_list,'./model/univariate-LSTM-model-result-Copy1.h5',old_data_list,date_range_list)\n",
    "\n",
    "    predict_list.append(predict_result)\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    execute_time_list.append(end - start)\n",
    "    all_time_end = time.time()\n",
    "    print(\"執行時間：%f 秒\" % (all_time_end - all_time_start))\n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "coeff_predict_list = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train\n",
    "for i in range(int(len(date_range_list_1))):\n",
    "#     end_date = datetime.strptime(date_range_list_1[i],'%Y-%m-%d %H:%M:%S').date()\n",
    "    start_date = date_range_list_1[i]-timedelta(days=2)\n",
    "    sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(start_date, date_range_list_1[i])\n",
    "    dbh = MySQL()\n",
    "    all_data = dbh.query(sql)\n",
    "\n",
    "    dbh.close()\n",
    "    all_df = pd.DataFrame(all_data)\n",
    "    all_df = all_df.set_index('datetime')\n",
    "    \n",
    "    true=np.array(all_df['demand_quarter'].astype('float'))\n",
    "#     print(true_dataframe_Close)\n",
    "    predict_value = predict_date_range(true,date_range_list_1[i])\n",
    "    predict_list.append(predict_value)\n",
    "\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "coeff_predict_list = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train\n",
    "for i in range(int(len(date_range_list_2))):\n",
    "#     end_date = datetime.strptime(date_range_list_1[i],'%Y-%m-%d %H:%M:%S').date()\n",
    "    start_date = date_range_list_2[i]-timedelta(days=2)\n",
    "    sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(start_date, date_range_list_2[i])\n",
    "    dbh = MySQL()\n",
    "    all_data = dbh.query(sql)\n",
    "\n",
    "    dbh.close()\n",
    "    all_df = pd.DataFrame(all_data)\n",
    "    all_df = all_df.set_index('datetime')\n",
    "    \n",
    "    true=np.array(all_df['demand_quarter'].astype('float'))\n",
    "#     print(true_dataframe_Close)\n",
    "    predict_value = predict_date_range(true,date_range_list_2[i])\n",
    "    predict_list.append(predict_value)\n",
    "\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f92c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "coeff_predict_list = []\n",
    "all_time_start = time.time()\n",
    "# train_coefficient_append = train\n",
    "for i in range(int(len(date_range_list_3))):\n",
    "#     end_date = datetime.strptime(date_range_list_1[i],'%Y-%m-%d %H:%M:%S').date()\n",
    "    start_date = date_range_list_3[i]-timedelta(days=2)\n",
    "    sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "                FROM `demand_with_weather_data` \n",
    "                WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "                ORDER BY `datetime` '''.format(start_date, date_range_list_3[i])\n",
    "    dbh = MySQL()\n",
    "    all_data = dbh.query(sql)\n",
    "\n",
    "    dbh.close()\n",
    "    all_df = pd.DataFrame(all_data)\n",
    "    all_df = all_df.set_index('datetime')\n",
    "#     print(date_range_list_1[i])\n",
    "    \n",
    "    \n",
    "#     true_dataframe_Close = yf.download('^TWII',start=start_date,end=date_range_list_1[i])\n",
    "#     true_dataframe_Close = true_dataframe_Close['Close']\n",
    "#     true_dataframe_Close = pd.DataFrame(true_dataframe_Close)\n",
    "    \n",
    "    true=np.array(all_df['demand_quarter'].astype('float'))\n",
    "#     print(true_dataframe_Close)\n",
    "    predict_value = predict_date_range(true,date_range_list_3[i])\n",
    "    predict_list.append(predict_value)\n",
    "\n",
    "all_time_end = time.time()\n",
    "print(\"全部執行時間：%f 秒\" % (all_time_end - all_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df663f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''SELECT  `demand_quarter`, `datetime`\n",
    "            FROM `demand_with_weather_data` \n",
    "            WHERE `datetime` >= '{}' AND `datetime` < '{}'\n",
    "            ORDER BY `datetime` '''.format(start_day_1, end_day_1)\n",
    "dbh = MySQL()\n",
    "data = dbh.query(sql)\n",
    "\n",
    "dbh.close()\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('datetime')\n",
    "#     print(date_range_list_1[i])\n",
    "\n",
    "\n",
    "#     true_dataframe_Close = yf.download('^TWII',start=start_date,end=date_range_list_1[i])\n",
    "#     true_dataframe_Close = true_dataframe_Close['Close']\n",
    "#     true_dataframe_Close = pd.DataFrame(true_dataframe_Close)\n",
    "\n",
    "true=np.array(df['demand_quarter'].astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83291d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(true)\n",
    "plt.plot(np.array(predict_list).ravel(),c='g')\n",
    "plt.legend(['data', 'LSTM_prediction'], loc='upper right')\n",
    "# plt.plot(predict_list,c='g')\n",
    "\n",
    "plt.ylim([100,350])\n",
    "plt.show()\n",
    "\n",
    "k = true\n",
    "r = np.array(predict_list).ravel()\n",
    "\n",
    "LSTM_R2 = r2_score(k,r)\n",
    "LSTM_MSE = mean_squared_error(k,r)\n",
    "LSTM_MAE = mean_absolute_error(k,r)\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(true)\n",
    "plt.plot(np.array(predict_list).ravel(),c='g')\n",
    "\n",
    "# plt.plot(predict_list,c='g')\n",
    "\n",
    "# plt.ylim([14000,16000])\n",
    "plt.show()\n",
    "\n",
    "k = true\n",
    "r = np.array(predict_list).ravel()\n",
    "\n",
    "LSTM_R2 = r2_score(k,r)\n",
    "LSTM_MSE = mean_squared_error(k,r)\n",
    "LSTM_MAE = mean_absolute_error(k,r)\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f95656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10 ,5))\n",
    "# plt.ylim([13500,20000])\n",
    "# plt.xlim([1,200])\n",
    "# plt.ylim([12000,19000])\n",
    "plt.plot(true)\n",
    "plt.plot(np.array(predict_list).ravel(),c='g')\n",
    "\n",
    "# plt.plot(predict_list,c='g')\n",
    "\n",
    "# plt.ylim([14000,16000])\n",
    "plt.show()\n",
    "\n",
    "k = true\n",
    "r = np.array(predict_list).ravel()\n",
    "\n",
    "LSTM_R2 = r2_score(k,r)\n",
    "LSTM_MSE = mean_squared_error(k,r)\n",
    "LSTM_MAE = mean_absolute_error(k,r)\n",
    "LSTM_MRE = np.mean(np.abs((k - r) / k)) * 100\n",
    "print(\"LSTM_R2=\",LSTM_R2)\n",
    "print(\"LSTM_MSE=\",LSTM_MSE)\n",
    "print(\"LSTM_MAE=\",LSTM_MAE)\n",
    "print(\"LSTM_RMSE=\",sqrt(LSTM_MSE))\n",
    "print(\"LSTM_MRE=\",LSTM_MRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fca376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
